{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Wimbledon_featured_matches.csv\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 独热编码列: 'serve_width', 'winner_shot_type'\n",
    "for column in ['serve_width', 'winner_shot_type']:\n",
    "    insert_loc = data.columns.get_loc(column)\n",
    "    data = pd.concat([data.iloc[:,:insert_loc], pd.get_dummies(data.loc[:, [column]]), data.iloc[:,insert_loc+1:]], axis=1)\n",
    "# Replace 'NCTL' with 0 and 'CTL' with 1 in 'serve_depth' column\n",
    "data['serve_depth'] = data['serve_depth'].replace({'NCTL': 0, 'CTL': 1})\n",
    "# Replace 'ND' with 0.5 and 'D' with 1 in return_depth\n",
    "data['return_depth'] = data['return_depth'].replace({'ND': 0.5, 'D': 1})\n",
    "# Fill missing values in return_depth with 0\n",
    "data['return_depth'].fillna(0, inplace=True)\n",
    "# Fill missing values in speed_mph with 0\n",
    "data['speed_mph'].fillna(0, inplace=True)\n",
    "# Fill missing values in serve_depth with 0\n",
    "data['serve_depth'].fillna(0, inplace=True)\n",
    "# Drop columns which are before 'server'\n",
    "m,n = data.shape\n",
    "dic_column = dict(zip(data.columns, range(n)))\n",
    "data.drop(data.columns[list(range(dic_column[\"server\"]))], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns_p1 = []\n",
    "data_columns_p2 = []\n",
    "for column in data.columns:\n",
    "    if column.startswith('p1'):\n",
    "        data_columns_p1.append(column)\n",
    "    elif column.startswith('p2'):\n",
    "        data_columns_p2.append(column)\n",
    "    else:\n",
    "        data_columns_p1.append(column)\n",
    "        data_columns_p2.append(column)\n",
    "\n",
    "data_p1 = data[data_columns_p1]\n",
    "data_p2 = data[data_columns_p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 300, 501, 635, 972, 1218, 1550, 1782, 1972, 2185, 2503, 2673, 2948, 3238, 3423, 3621, 3788, 4013, 4287, 4409, 4695, 4910, 5105, 5436, 5707, 5896, 6179, 6372, 6589, 6748, 6950, 7283]\n"
     ]
    }
   ],
   "source": [
    "# Add a column named 'momentum' with all values set to 0\n",
    "data['momentum'] = np.nan\n",
    "m,n = data.shape\n",
    "dic_column = dict(zip(data.columns, range(n)))\n",
    "new_match_start = []\n",
    "for i in range(m):\n",
    "    if data.iloc[i,dic_column[\"elapsed_time\"]] == \"00:00:00\":\n",
    "        new_match_start.append(i)\n",
    "new_match_start.append(m-1)\n",
    "print(new_match_start)\n",
    "for i in range(len(new_match_start)-1):\n",
    "    data.iloc[new_match_start[i], dic_column['momentum']] = 0\n",
    "    start = new_match_start[i]\n",
    "    end = new_match_start[i+1]\n",
    "    for j in range(start+1, end+1):\n",
    "        if data.iloc[j, dic_column['server']] == data.iloc[j-1, dic_column['point_victor']]:\n",
    "            data.iloc[j, dic_column['momentum']] = 1\n",
    "        else:\n",
    "            data.iloc[j, dic_column['momentum']] = 0\n",
    "data.iloc[new_match_start[-1], dic_column['momentum']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m col_min \u001b[38;5;241m=\u001b[39m data[j]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m      5\u001b[0m col_max \u001b[38;5;241m=\u001b[39m data[j]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m----> 6\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mcol_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol_min\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      8\u001b[0m     data2[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# 熵权法\n",
    "n, m = data.shape\n",
    "data2 = pd.DataFrame(np.zeros((n, m)), columns=data.columns, index=data.index)\n",
    "for j in data.columns:\n",
    "    col_min = data[j].min()\n",
    "    col_max = data[j].max()\n",
    "    diff = col_max - col_min\n",
    "    if diff == 0:\n",
    "        data2[j] = 0.0001\n",
    "    else:\n",
    "        data2[j] = (data[j] - col_min) / diff\n",
    "        data2.loc[data2[j] == 0, j] = 0.0001\n",
    "\n",
    "p = data2.div(data2.sum(axis=0), axis=1)\n",
    "e = - (p * np.log(p)).sum(axis=0) / np.log(n)\n",
    "g = 1 - e\n",
    "w = g / g.sum()\n",
    "s = w.values @ p.values.T\n",
    "ss = -np.sort(-s)\n",
    "rank = np.argsort(-s) + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
